---
title: "Systematic survey of literature using deep learning for animal image analysis at individual and ecological scales"
authors: "M. Lagisz"
date: "February 2022"
output:
  html_document:
    toc: true
    toc_depth: 4
    number_sections: false
    toc_float:
      collapsed: false
      smooth_scroll: false
    fig.align: "center"
    fig_caption: true
    error: false
    warning: false
    message: false
    echo: false
    tidy: true
    cache: true
    df_print: paged
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, warning = F, message = F)
pacman::p_load(here, magrittr, tidyr, stringr, ggplot2, cowplot, tidyverse, here, readxl, bibliometrix, igraph, data.table, ggalluvial, rworldmap, rotl, ape, rphylopic)
#library(patchwork),  # for arranging ggplots in panels
library(devtools)
#devtools::install_github('Mikata-Project/ggthemr')
#devtools::install_github('cttobin/ggthemr')
library(ggthemr) #see https://github.com/Mikata-Project/ggthemr#palettes
# to remove all ggthemr effects later:
#ggthemr_reset()
ggthemr('fresh') #select one ggplot theme to be used
```


## Aims  
The main objective of this systematic literature survey was to identify gaps and trends in a representative sample of published studies using deep-learning algorithms to analyse image data for animals species/individual/behaviour recognition and/or classification. To gain insights on recent developments aresented in academic literature, we focused on the journal articles and full-text conference proceedings published in the last 5 years (2017-2021).   

## Literature search  
We run a search in Scopus on 2021/10/10 using a pre-piloted search string (for details on the development including validation set refer a dedicated Notion notebook - **ADD DETAILS LETER?**):   

( TITLE-ABS-KEY ( ( \*automatic\* OR "machine learning" OR "computer learning" OR "deep learning" OR "neural network\*" OR "random forest\*" OR "convolutional neural" OR "convolutional network\*" OR "learning algorithm\*" OR "Support Vector\*" ) AND ( image* OR camera* OR video* OR vision ) AND ( \*wild\* OR population* OR "species identif\*" OR "species label\*" OR "species richness" OR ( bahavio* AND within/ 10 classif* ) OR ( bahavio* AND within/ 10 recogn* ) ) AND NOT ( "natural language" OR "sign language" OR accelomet* OR clinical* OR industr* OR agricult* OR farm* OR leaf OR husbandry OR food* OR tissue* OR cell* OR cultur* OR wildfire* OR "tree growth" OR forestry OR hydrolog* OR engineer* OR "oxygen species" OR molec* OR bacteria* OR microb* OR chemi* OR spectrom* OR brain* OR drug* OR patient* OR cancer* OR smoking OR disease OR diabet* OR landsat* OR sentinel OR satellite* OR "land cover" OR "land use" OR "vegetation map\*" OR galax\* OR "Google Earth" OR scan* OR "X-ray" OR "health care" OR participant* OR emotion* OR employee* OR speech OR proceedings ) ) ) AND PUBYEAR > 2016    

The search retrieved **2,259** bibliographic records that were then downloaded and screened for inclusion.    

## Inclusion criteria at the title and abstract screening phase   

Following PICO framework, we included articles if all criteria below were fulfilled: 

- **Population:** wild or semi-wild vertebrate species (exclude domestic or farmed animals, invertebrates, museum specimens).   

- **Intervention** / **Innovation:** use of computer vision machine learning algorithms (include neural-network type methods, such as deep learning, CNN), support vector, random forest) for automated or semi-automated processing of image data (e.g. from camera traps, video tracking, thermal imaging) at a scale where individual animals are visible (include aerial and drone images (exclude images gathered from satellites, biologing, X-ray, MRI images or equivalent).   

- **Comparator** / **Context**: images taken in the wild or semi-wild (includes zoo enclosures, excludes lab-based or agricultural/aquaculture/pet studies).   

- **Outcomes**: analyses focus on animal / species individual recognition/classification or animal behaviour recognition/classification.   

- Additional criteria: studies published in last 5 years (2017-2021), peer-reviewed (including full-text conference proceedings).   

## Abstract screening procedure and results   
We used Rayyan QCRI software to screen 2,259 unique bibliographic records downloaded from Scopus. Two researchers (ML, JT) independently performed the screening assessing titles abstracts and keywords of each article. This screening resulted in 225 articles included for full-text assessment and data extraction.   

## Inclusion criteria at full-text screening   
- Full text available   
- Full-text studies should fulfill the same criteria as defined for the title and abstract screening phase   

## Full text screening and data extraction   
Out of the 225 papers included, we obtained full-text for 215 papers.   
For data extraction we used a two-part custom questionnaire implemented as a Google Form ( https://forms.gle/N7Hn9DVRjjmoKRd58). To pilot the form, we randomly selected 14 papers for independent screening aand extraction by three researchers (ML, JT, RF). We resolved disagreements by discussion until consensus was reached, and we refined the questionnaire form before the main round of full-text screening and data extraction.  
One researcher (ML) performed full-text screening and data extraction for the remaining 195 papers. Second researcher (RF) cross-checked 58 of these papers for accuracy and to potentially resolve cases where information provided in the papers was unclear. After the full-text assessment, we extracted data from 192 studies.


#### Table S1 - full-text assessment and data extraction form 
Question                   | Answer options  
---------------------------| -------------- 
Paper's title:	| [text]   
First author's family name: | [text]   
Publication year: | [number]   
Journal name:	 |[text]     
Article doi: |  [text] 	
C1. Peer-reviewed empirical study | [yes; no; unsure/other]  		
Comment for C1 |   		
C2. Is full text available in English? |  [yes; no; unsure/other] 		
Comment for C2 |   		
C3. Population: wild or semi-wild vertebrate species? | [yes; no; unsure/other]  		
Comment for C3 |   		
C4. Intervention / Innovation: use of computer vision machine learning algorithms (for automated or semi-automated processing of image data at a scale where individual animals are visible)?: |  [yes; no; unsure/other] 	 
Comment for C4 |   		
C5. Comparator / Context: are the studied animals in the wild or semi-wild?	comment for C5 |  [yes; no; unsure/other]  		
C6. Outcomes: focus on animal / species individual recognition / classification or animal behaviour recognition / classification ?: | [yes; no; unsure/other]    		
Comment for C6 |   		
Q1. Number of studied species | [number]  	
Comment for Q1 |   		
Q2. Study species	(Latin name) | [text]    
Comment for Q2 |   		
Q3. Studied species group: | [mammals; birds; reptiles; amphibians; fishes; other/unclear]*  	
Comment for Q3 |   		
Q4. Used image type source: | [camera trap or surveillance camera (fixed); aerial (including drone); hand camera (or mobile phone camera); other/unclear]*  		
Comment for Q4 |   		
Q5. Study context or setting: | [wild; semi-wild; unclear/other]*  		
Comment for Q5 |  
Q6. Location country/region: | [text]     
Q7. Location details: | [text]	   
Q8. Algorithm type: | [Neural Network; Random forest; Gradient boosting model; Support Vector Machines; Rule-based learners; Decision trees; K-Nearest Neighbour; unclear/other]*    
Q9. Outcome type:	 | [counting individuals (at given time); individual recognition (re-identification); species recognition/classification (class/object detection); behaviour detection (at given time); tracking (following through space); behaviour classification (changes over time); unclear/other]*  
Q10. Analysis code | [yes; no; unclear/other]   	

----
*Note:* * indicates plural variables (i.e. more than one answer option can be chosen).

Each question in the data extraction form (**Table S1**) is followed by a dedicated comment field used to record any additional details, including relevant quotes from the paper. We excluded any papers that were coded as "no" at questions C1 to C6 (full-text screening questions - whether the paper fulfills our inclusion criteria), i.e. these papers were not subject to any further data extraction and analyses.  

After data extraction additional columns were added to the data table with the following data:   
 - Q7_coordinates: latitude and longitude of the study location, as in the paper or from Google Maps, if not reported      
 - Q7_location_unclear: 0 = clear (location at least at the level of national park, state, province, city, or equivalent - reported in the article or inferred from the data set name); 1 = unclear, location either not reported or cannot be assigned to a specific location (e.g., global data, broad regions such as Arctic, Northern Atlantic, Africa, America)   
 - Checked: whether record was cross-checked by an indpendent researcher	   
 - Checking_comments: any comments from data extraction checking	  
 - Changed:	whether record was changed after cross-checking    
 - Changed_comment:	how record was changed after cross-checking   
 - Pilot: whether study was used in the piloting phase	  
 - Included: whether study was included in the final data set for extraction    
 - Exclusion reason: main reason for excluding study from the final data set for extraction, if excluded     

## Screening results  
Out of the 215 full-text articles screened, 192 were deemed eligible for data extraction (**Table S2**). The data extraction spreadsheet is stored as *mapping_dataset_reconciled.xlsx*. Below, we present a summary of the extracted data.   

```{r load data}
rawdata <- read_excel(here("data", "mapping_dataset_reconciled.xlsx"), sheet = 1)
# dim(rawdata) #225 rows 47 columns
# names(rawdata)
# View(rawdata) # taking a quick look
```

### Summary tables 

#### Table S2
List of articles excluded at full-text screening, with main reasons for exclusion.     
```{r data table excluded articles}
#table(rawdata$"exclusion_reason") #table of exclusion resons for the excluded studies

#remove 46 included studies and select a few relevant columns
rawdata_excl <- rawdata %>% filter(Included == "0") %>% select(c("First author's family name:", "Publication year:", "Paper's title:", "Journal name:" , "Article doi:", "Exclusion reason")) 
#dim(rawdata_excl) #16 articles, 6 columns
#names(rawdata_excl)
names(rawdata_excl) <- c("First_author", "Year",  "Title", "Journal", "DOI", "Exclusion_reason")

#make a table of excluded  studies
t2 <- rawdata_excl %>%   DT::datatable(rownames = FALSE, width = "100%", options = list(dom = 't', scrollY = '700px', pageLength = 20))
t2
```

#### Table S3
List of included articles with key bibliographic information.   
```{r data table included articles}
#remove 4 excluded studies and remove all columns with "Comment", "checked" and then first 2 columns
rawdata_incl <- rawdata %>% filter(Included == "1") %>% select(c("First author's family name:", "Publication year:", "Paper's title:", "Journal name:" , "Article doi:")) 

#make a table of included studies
names(rawdata_incl) <- c("First_author", "Year",  "Title", "Journal", "DOI")
t3 <- rawdata_incl %>% DT::datatable(rownames = FALSE, width = "100%", options = list(dom = 't', scrollY = '700px', pageLength = 20)) 
t3
```

### Preprocessing extracted data    

Data cleaning before generating summaries and plotting.      

```{r clean data}

#remove unnecessary columns
rawdata_incl <- rawdata %>% filter(Included == "1") %>% select(-starts_with("C")) %>% select(-c("Timestamp", "Respondent's initials:", "Pilot", "Included", "Exclusion reason"))

#replace column names with shorter variable names for rawdata_incl analyses
names(rawdata_incl) <- c("Title",
                 "Author",
                 "Year",
                 "Journal",
                 "DOI",
                 "Species_number",
                 "Study_species",
                 "Studied_species_type",
                 "Image_source_type",
                 "Study_setting",
                 "Location_country",
                 "Location_details",
                 "Location_coordinates",
                 "Location_unclear",
                 "Algorithm_type",
                 "Outcome_type",
                 "Analysis_code")
```


### Summaries and plots

#### Publication year

```{r plot year, fig.dim = c(8, 2)}
count(rawdata_incl, Year) %>%
  mutate(class = factor(Year, levels = Year)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
#  geom_text(aes(label=scales::comma(n)), hjust = 0, nudge_y = 1) +
#  coord_flip() +
  scale_y_continuous(breaks = seq(0, 60, 10)) +
  labs(x = "", y = "Article count", title = "When it was published?")

# ggsave(filename = "./figures/FigS01.pdf",
#        plot = plot_qual,
#        height = 5, width = 10,
#        device = cairo_pdf)
```

#### Top 20 publication journals

A barplot of the counts  of publications in different journals, with top 20 shown sorted by descending frequency order.   

```{r plot journal, fig.dim = c(16, 14)}
count(rawdata_incl, Journal) %>%
  arrange(n) %>% top_n(20) %>%
  mutate(class = factor(Journal, levels = Journal)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
 # geom_text(aes(label = scales::comma(n)), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 20, 1)) +
  labs(x = "", y = "Article count", title = "Where it was published?")
```

To infer discipline / audience type we categorized publicatio journals as: computer science / technology, ecology, multidisciplinary. 

```{r journal discipline, include = FALSE}
# classify journals into comp.sci vs. ecology journals
unique(rawdata_incl$Journal)
rawdata_incl$Journal_discipline <- 
  recode(rawdata_incl$Journal, "Behavioral Ecology and Sociobiology" = "ecology", "Ethology" = "ecology", "Global Ecology and Conservation" = "ecology", "Integrative Zoology" = "ecology", "Mammal Study" = "ecology", "Wildlife Society Bulletin" = "ecology", "Journal of Coastal Research" = "ecology", "Condor" = "ecology", "Methods in Ecology and Evolution" = "ecology", "Environmental Monitoring and Assessment" = "ecology", "Remote Sensing in Ecology and Conservation" = "ecology", "Ornis Fennica" = "ecology", "Ecology and Evolution" = "ecology", "European Journal of Wildlife Research" = "ecology", "Frontiers in Marine Science" = "ecology", "Conservation Biology" = "ecology", "Animals" = "ecology", "Ecological Informatics" = "ecology", "Scientific Reports" = "multidisciplinary", "Science Advances" = "multidisciplinary", "Proceedings of the National Academy of Sciences of the United States of America" = "multidisciplinary", .default = "computer science / technology")
table(rawdata_incl$Journal_discipline)
```

```{r journal discipline plot, fig.dim = c(8, 2)}
rawdata_incl %>% 
  filter(!is.na(Journal_discipline)) %>% 
  count(Journal_discipline) %>%
  arrange(n) %>%
  mutate(class = factor(Journal_discipline, levels = Journal_discipline)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = as.integer(scales::comma(n))), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 150, 10)) +
  labs(x = "", y = "Article count", title = "What disciplines journals represent?")
```

#### Number of species / animal classes used 

Most data sets have prespecified number of animal species / classes present. Class can represent a species or a higher taxonomic group, such as genus, family, order, super-order, etc. (even "animals" can ba a class). Classes of non-animal objects (e.g. humans, vehicles) were not counted. When more than one dataset was used, the number was extracted for the biggest dataset.     

As a histogram with numbers of classes on a log x-scale due to strong right-skew in the data.   

```{r plot Species_number histogram, fig.dim = c(8, 4)}
#table(rawdata_incl$Species_number == "NA") #13 values of NA = no information in the paper
#table(as.integer(rawdata_incl$Species_number), useNA = "always")

## plot as a histogram
rawdata_incl %>% 
  filter(Species_number != "NA") %>% 
  select(Species_number) %>% 
  ggplot(aes(x = as.integer(Species_number))) + 
  geom_histogram() +
  scale_x_log10() +
  labs(x = "Number", y = "Article count", title = "Number of species/animal classes?")
 #geom_histogram(binwidth = 100) +
 #scale_x_continuous(breaks = seq(0, 20000, 1000))
```

As a barplot displaying actual values of the numbers of species / classes.

```{r plot Species_number barplot, fig.dim = c(8, 6)}
## plot with actual numbers
count(rawdata_incl, Species_number) %>%
  arrange(as.integer(Species_number)) %>% #top_n(100) %>%
  mutate(class = factor(Species_number, levels = Species_number)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
 # geom_text(aes(label = scales::comma(n)), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 100, 10)) +
  labs(x = "", y = "Article count", title = "Number of species/animal classes?")
```

#### Study species in one-animal studies    

For studies focusing on a single animal species, we extracted species name to investigate which particular species were most popular (subspecies names are omitted from the plot labels).       

```{r plot study species one, fig.dim = c(8, 6)}
#table(rawdata_incl$Study_species != "many", useNA = "always") #59 values of species name for one-species studies, 133 with more than one species /animal classes used
#table(rawdata_incl$Study_species, useNA = "always")

## fix typos in the names and remove subspecies names
rawdata_incl$Study_species <- gsub("Phascolarctus cinereus", "Phascolarctos cinereus", rawdata_incl$Study_species)
rawdata_incl$Study_species <- gsub("Frlis catus domesticus", "Felis catus", rawdata_incl$Study_species)
rawdata_incl$Study_species <- gsub("Panthera tigris altaica", "Panthera tigris", rawdata_incl$Study_species)
rawdata_incl$Study_species <- gsub("Pan troglodytes verus", "Pan troglodytes", rawdata_incl$Study_species)
rawdata_incl$Study_species <- gsub("Python molurus bivittatus", "Python molurus", rawdata_incl$Study_species)
rawdata_incl$Study_species <- gsub("Sousa chinensis taiwanensis", "Sousa chinensis", rawdata_incl$Study_species)
rawdata_incl$Study_species <- gsub("Ursus arctos maritimus", "Ursus arctos", rawdata_incl$Study_species)
rawdata_incl$Study_species <- gsub("Pusa hispida saimensis", "Pusa hispida", rawdata_incl$Study_species)
rawdata_incl$Study_species <- gsub("Phoca hispida saimensis", "Pusa hispida", rawdata_incl$Study_species)

rawdata_incl %>% filter(Species_number == "1") %>% 
  filter(Study_species != "unclear") %>% 
  count(Study_species) %>%
  arrange(n) %>%
  mutate(class = factor(Study_species, levels = Study_species)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
 # geom_text(aes(label=scales::comma(n)), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 20, 1)) +
  labs(x = "", y = "Article count", title = "Most popular species in single-species studies?")
```

#### Types of animals used    

Most popular types of animals as represented by commonly used "biological" categories. One study could be coded as studging one or more categories of animals, e.g. both mammals and birds. However, distribution of number of species within multi-category studies was often not even, e.g. a commonly used Serengeti dataset from tanzania is dominated by large mammals with only a few species of large birds considered in analyses.    

```{r plot study species types, fig.dim = c(8, 3)}
#table(rawdata_incl$Studied_species_type, useNA = "always") #1 NA, need to split at comma

Studied_species_type_sep <- separate_rows(rawdata_incl, Studied_species_type, sep = ", ") #split rows with multiple values
#table(Studied_species_type_sep$Studied_species_type, useNA = "always") #1 NA
Studied_species_type_sep$Studied_species_type <- replace_na(Studied_species_type_sep$Studied_species_type, "unclear") #fix NA

Studied_species_type_sep$Studied_species_type <- as.factor(Studied_species_type_sep$Studied_species_type)

Studied_species_type_sep %>% 
  filter(!is.na(Studied_species_type)) %>% 
  count(Studied_species_type) %>%
  arrange(n) %>%
  mutate(class = factor(Studied_species_type, levels = Studied_species_type)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = as.integer(scales::comma(n))), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 150, 10)) +
  labs(x = "", y = "Article count", title = "What types of animals were studied?", caption = "Note: some studies used more than one")

```

#### Types of image sources used    

Image sources were categorized by the type of the hardware used to collect image  data: fixed survelliance/trap cameras (often activated by movement, or continuously recording), hand-held devices including mobile phones, or device mounted on aerial vehicles including drones. Where it was not clearly reported in a paper, we inferred the image source from the example images from the analysed dataset or from descriptions of the dataset in other publications. A single study could be coded as using one or more categories of image sources, e.g. mix of camera traps and hand-held cameras.   

```{r plot study image source types, fig.dim = c(8, 2)}
#table(rawdata_incl$Image_source_type, useNA = "always") #0 NA, need to split at comma
Image_source_type_sep <- separate_rows(rawdata_incl, Image_source_type, sep = ", ") #split rows with multiple values
Image_source_type_sep$Image_source_type <- as.factor(Image_source_type_sep$Image_source_type)
#table(Image_source_type_sep$Image_source_type, useNA = "always") #1 NA

Image_source_type_sep %>% 
  filter(!is.na(Image_source_type)) %>% 
  count(Image_source_type) %>%
  arrange(n) %>%
  mutate(class = factor(Image_source_type, levels = Image_source_type)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = as.integer(scales::comma(n))), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 150, 10)) +
  labs(x = "", y = "Article count", title = "What types of images were studied?", caption = "Note: some studies used more than one type")
```

#### Types of settings for animal images       

Settings of teh images used were classified as wild or semi-wold (outdoor enclusures for wild animals).  A single study could be coded as using one or more categories of settings, e.g. mix of images from te wild and captive animals.   

```{r plot study setting types, fig.dim = c(8, 2)}
#table(rawdata_incl$Study_setting, useNA = "always") #0 NA, need to split at comma
rawdata_incl$Study_setting <- recode(rawdata_incl$Study_setting, "unclear/other" = "other / unclear") #standarise

Study_setting_sep <- separate_rows(rawdata_incl, Study_setting, sep = ", ") #split rows with multiple values
Study_setting_sep$Study_setting <- as.factor(Study_setting_sep$Study_setting)
#table(Study_setting_sep$Study_setting, useNA = "always") 

Study_setting_sep %>% 
  filter(!is.na(Study_setting)) %>% 
  count(Study_setting) %>%
  arrange(n) %>%
  mutate(class = factor(Study_setting, levels = Study_setting)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = as.integer(scales::comma(n))), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 150, 10)) +
  labs(x = "", y = "Article count", title = "What types of settings were studied?", caption = "Note: some studies used more than one")
```

#### Location country  

Country or a larger region where animal images were collected. A single study could be coded as using images from one or more countries/regions. Some studies using images of captive animals kept in zoos likely across mutiple countries were coded as "global" (often images sourced from the Internet/social platforms).   
 
```{r clean location country names}
#table(rawdata_incl$Location_country, useNA = "always") #0 NA, need to fix some names
rawdata_incl$Location_country <- gsub("Botswanam Australia", "Botswana, Australia", rawdata_incl$Location_country)
rawdata_incl$Location_country <- gsub("Falkland \\(Malvinas\\) Islands", "Falkland Islands", rawdata_incl$Location_country)
rawdata_incl$Location_country <- gsub("Asutralia", "Australia", rawdata_incl$Location_country)
rawdata_incl$Location_country <- gsub("Soith Africa", "South Africa", rawdata_incl$Location_country)
rawdata_incl$Location_country <- gsub("The Netherlands" , "Netherlands" , rawdata_incl$Location_country)
rawdata_incl$Location_country <- gsub("NZ", "New Zealand", rawdata_incl$Location_country)
rawdata_incl$Location_country <- gsub("Korea", "South Korea", rawdata_incl$Location_country)
rawdata_incl$Location_country <- gsub("Congo", "Republic of Congo", rawdata_incl$Location_country)
rawdata_incl$Location_country <- gsub("UAE", "United Arab Emirates", rawdata_incl$Location_country)

Location_country_sep <- separate_rows(rawdata_incl, Location_country, sep = ", ") #split rows with multiple values
Location_country_sep$Location_country <- as.factor(Location_country_sep$Location_country) #as factor
#table(Location_country_sep$Location_country, useNA = "always") 
#unique(Location_country_sep$Location_country)
```

A barplot of the counts of articles originating form a given country / larger region. "Global" are usually datasets based on images collected from the Internet or social media.    

```{r plot location country barplot, fig.dim = c(8, 6)}

Location_country_sep %>% 
  filter(Location_country!="unclear") %>% 
  count(Location_country) %>%
  arrange(n) %>%
  mutate(class=factor(Location_country, levels = Location_country)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
 # geom_text(aes(label = scales::comma(n)), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0,30,5)) +
  labs(x = "", y = "Article count", title = "Most popular location country/region?", caption = "Note: some studies used more than one")
```

A choropleth map of the counts of articles based on a dataset originating form a given country. Data gathered from larger than country regions (e.g. oceans, continents, global) are not shown.   

```{r plot location country map, fig.dim = c(8, 4)}

map.world <- map_data("world")
#intersect(map.world$region, Location_country_sep$Location_country) #41 out of 48 found
#setdiff(Location_country_sep$Location_country, map.world$region) #7 out of 41 not found: oceans and broader regions

Location_country_sep %>% 
  filter(!is.na(Location_country)) %>% 
  count(Location_country) -> Location_country_counts
#str(Location_country_counts)    

map.world_joined <- left_join(map.world, Location_country_counts, by = c('region' = 'Location_country'))

ggplot(map.world_joined, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = n ), color = "white") +
  scale_fill_viridis_c(option = "E") +
  labs(title = 'Most popular location country?') 
```

#### Location coordinates

Location coordinates represent either a specific location (green circles) or centroids of a broader region (orange circles) animal images originated from. Darker circles indicate a larger number of studies using images from a given location. Global image datasets (e.g. gathered from the Internet or social media) are not shown.    

```{r clean location coordinates}
#table(rawdata_incl$Location_unclear, useNA = "always") #1 = yes for 78 studies, 3 is NA (global or multi-location studies)
#table(is.na(rawdata_incl$Location_coordinates), useNA = "always") #133 has coordinates, 59 has no

#table(rawdata_incl$Study_setting, rawdata_incl$Location_unclear, useNA = "always") #97+7 wild/semi-wild have clear location
#table(is.na(rawdata_incl$Location_coordinates), rawdata_incl$Location_unclear, useNA = "always") #110 has coordinates and clear location, 56 of 78 with unclear location have no coordinates
#table(is.na(rawdata_incl$Location_coordinates), rawdata_incl$Study_setting, useNA = "always") #116 of the wild-based studies has coordinates

# plot dots at coordinates for wild-based studies only - filter data and split coordinates column into longitude and latitude:
rawdata_incl %>% filter(Study_setting == "wild" | Study_setting == "wild, semi-wild") %>% filter(is.na(Location_coordinates) == FALSE) %>% separate(col = Location_coordinates, into = c("Latitude", "Longitude") , sep = ", ") -> coordinates_sep

#fix typo in a coordinate
coordinates_sep$Longitude <- gsub("âˆ’ 28.169438", "-28.169438", coordinates_sep$Longitude)
coordinates_sep$Longitude <- as.numeric(coordinates_sep$Longitude)
coordinates_sep$Latitude <- as.numeric(coordinates_sep$Latitude)
coordinates_sep$Approximate_location <- recode(coordinates_sep$Location_unclear, "0" = "no", "1" = "yes")
```

```{r plot location coordinates, fig.dim = c(8, 4)}
#base don https://datavizpyr.com/how-to-make-world-map-with-ggplot2-in-r/

ggplot() +
  geom_map(
    data = map.world_joined, map = map.world_joined,
    aes(long, lat, map_id = region),
    color = "white", fill = "lightgray", size = 0.1
  ) +
  geom_point(
    data = coordinates_sep,
    aes(Longitude, Latitude, color = Approximate_location), size = 4,
    alpha = 0.4, position = position_jitter(width = 2, height = 2)
  )  +
  scale_colour_manual(values = c("darkgreen", "orange")) +
  theme(legend.position = "top")
```

#### Types of machine learning algorithm for analysing animal images    

Barplot of the main types of machine learning algorithms used. A single study could be coded as using one or more types.     

```{r plot algorithm type, fig.dim = c(8, 3)}
#table(rawdata_incl$Algorithm_type, useNA = "always") #0 NA, need to split at comma
Algorithm_type_sep <- separate_rows(rawdata_incl, Algorithm_type, sep = ", ") #split rows with multiple values
#table(Algorithm_type_sep$Algorithm_type, useNA = "always") #0 NA
Algorithm_type_sep$Algorithm_type <- recode(Algorithm_type_sep$Algorithm_type, "unclear/other" = "other / unclear")

Algorithm_type_sep$Algorithm_type <- as.factor(Algorithm_type_sep$Algorithm_type)

Algorithm_type_sep %>% 
  filter(!is.na(Algorithm_type)) %>% 
  count(Algorithm_type) %>%
  arrange(n) %>%
  mutate(class = factor(Algorithm_type, levels = Algorithm_type)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = as.integer(scales::comma(n))), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 200, 50)) +
  labs(x = "", y = "Article count", title = "What types of algorithms were used?", caption = "Note: some studies used more than one")
```

#### Types of outcomes from analysing animal images    

Barplot of the main types of outcomes / purposes of analyses used. A single study could be coded as using one or more types.    

```{r plot outcome type, fig.dim = c(8, 3)}
#table(rawdata_incl$Outcome_type, useNA = "always") #1 NA, need to split at comma
rawdata_incl$Outcome_type <- replace_na(rawdata_incl$Outcome_type, "species recognition/classification (class/object detection)") #fix NA
Outcome_type_sep <- separate_rows(rawdata_incl, Outcome_type, sep = ", ") #split rows with multiple values
#table(Outcome_type_sep$Outcome_type, useNA = "always") 
Outcome_type_sep$Outcome_type <- recode(Outcome_type_sep$Outcome_type, "unclear/other (add comment)" = "other / unclear")
Outcome_type_sep$Outcome_type <- as.factor(Outcome_type_sep$Outcome_type)

Outcome_type_sep %>% 
  filter(!is.na(Outcome_type)) %>% 
  count(Outcome_type,) %>%
  arrange(n) %>%
  mutate(class=factor(Outcome_type, levels = Outcome_type)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = as.integer(scales::comma(n))), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 200, 50)) +
  labs(x = "", y = "Article count", title = "What types of outcomes were analysed?", caption = "Note: some studies used more than one")
```

#### Whether analysis code is available    

Barplot of the analysis code availability. Code was coded as available when a link to a code repository was provided in the article.    

```{r plot analysis code shared, fig.dim = c(8, 2)}
#table(rawdata_incl$Analysis_code, useNA = "always") #0 NA, one value per study

rawdata_incl %>% 
  filter(!is.na(Analysis_code)) %>% 
  count(Analysis_code) %>%
  arrange(n) %>%
  mutate(class = factor(Analysis_code, levels = Analysis_code)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = as.integer(scales::comma(n))), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 200, 50)) +
  labs(x = "", y = "Article count", title = "Was analysis code shared?", caption = "Note: not checking if code complete or working")
```


#### Cross-tabulating two factors

A set of draft plots using information from two or more extracted variables. To be refined.    

##### Algorithm vs studied outcome heat map

A heatmap showing crosstabulation of the main types of machine learning algorithms and analysis outcomes / purposes. A single study could be coded as using one or more types for both variables.     

```{r plot algorythms and outcomes, fig.dim = c(8, 4)}
#dim(Outcome_type_sep) #285 18
Outcome_algorithm_type_sep <- separate_rows(Outcome_type_sep, Algorithm_type, sep = ", ") #split rows with multiple values
#dim(Outcome_algorithm_type_sep) #362 18
Outcome_algorithm_type_sep$Algorithm_type <- as.factor(Outcome_algorithm_type_sep$Algorithm_type)

Outcome_algorithm_type_sep %>% 
  filter(!is.na(Outcome_type)) %>% 
  count(Outcome_type, Algorithm_type) %>%
  ggplot(aes(x = Algorithm_type, y = Outcome_type, fill = n)) +
  geom_tile(color = "black") +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = n), color = "black", size = 4) +
  coord_fixed() +
  theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.text.y = element_text(angle = 45)) +
  labs(title = "Algorithm vs Outcome type")
```

##### Year vs studied outcome heat map

A heatmap showing crosstabulation of the study publication year and analysis outcomes / purposes. A single study could be coded as using one or more types for the analysis outcomes / purposes.  

```{r plot years and outcomes, fig.dim = c(8, 4)}
Outcome_type_sep %>% 
  filter(!is.na(Outcome_type)) %>% 
  count(Outcome_type, Year) %>%
  ggplot(aes(x = Year, y = Outcome_type, fill = n)) +
  geom_tile(color = "black") +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = n), color = "black", size = 4) +
  coord_fixed() +
  theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.text.y = element_text(angle = 45)) +
  labs(title = "Year vs outcome type")
```

##### Year vs studied outcome stacked area chart

A stacked area chart showing crosstabulation of the study publication year and analysis outcomes / purposes. A single study could be coded as using one or more types for the analysis outcomes / purposes.  

```{r plot years and outcomes stacked area, fig.dim = c(8, 6)}
# Give a specific order:
Outcome_type_sep$Outcome_type <- factor(Outcome_type_sep$Outcome_type, levels = c("other / unclear", "tracking (following through space)", "behaviour detection (at given time)", "behaviour classification (changes over time)", "individual recognition (re-identification)", "counting individuals (at given time)", "species recognition/classification (class/object detection)") )

Outcome_type_sep %>% 
  filter(!is.na(Outcome_type)) %>% 
  filter(Outcome_type != "unclear/other") %>%   
  count(Outcome_type, Year) %>%
  ggplot(aes(x = Year, y = n, fill = Outcome_type)) + 
  geom_area() +
  theme(legend.position = "bottom", legend.direction = "vertical") + 
  labs(x = "", y = "Article count", title = "Outcome type by year")
```

##### Year vs algorithm type heat map

A heatmap showing crosstabulation of the study publication year and the main types of machine learning algorithms. A single study could be coded as using one or more types for the types of machine learning algorithms.   

```{r plot years and algorithms heat map, fig.dim = c(8, 4)}
Algorithm_type_sep %>% 
  filter(!is.na(Algorithm_type)) %>% 
  count(Algorithm_type, Year) %>%
  ggplot(aes(x = Year, y = Algorithm_type, fill = n)) +
  geom_tile(color = "black") +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = n), color = "black", size = 4) +
  coord_fixed() +
  theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), axis.text.y = element_text(angle = 45)) +
  labs(title = "Year vs algorithm type")
```

##### Year vs algorithm type stacked area chart

A stacked area plot showing crosstabulation of the study publication year and the main types of machine learning algorithms. A single study could be coded as using one or more types for the types of machine learning algorithms.   

```{r plot years and algorithms stacked area, fig.dim = c(8, 6)}
# Give a specific order:
Algorithm_type_sep$Algorithm_type2 <- factor(Algorithm_type_sep$Algorithm_type, levels = c("other / unclear", "Random forest","Decision trees", "Gradient boosting model", "K-Nearest Neighbour", "Rule-based learners", "Support Vector Machines", "Neural Network") )

Algorithm_type_sep %>% 
  filter(!is.na(Algorithm_type2)) %>% 
  filter(Algorithm_type2 != "other / unclear") %>%   
  count(Algorithm_type2, Year) %>%
  ggplot(aes(x = Year, y = n, fill = Algorithm_type2)) + 
  geom_area() +
  theme(legend.position = "bottom", legend.direction = "vertical") + 
  labs(x = "", y = "Article count", title = "Algorithm type by year")
```

##### Year vs algorithm type proportional stacked area chart

A stacked area plot showing yearly changes in proportions of the main types of machine learning algorithms used. A single study could be coded as using one or more types for the types of machine learning algorithms.   


```{r plot years and algorithms proportional, fig.dim = c(8, 6)}
Algorithm_type_sep %>% 
  filter(!is.na(Algorithm_type)) %>% 
  filter(Algorithm_type != "other / unclear") %>%   
  count(Algorithm_type, Year) %>%
  group_by(Year, Algorithm_type) %>%
  summarise(nsum = sum(n)) %>%
  mutate(percentage = nsum / sum(nsum)) %>%
  ggplot(aes(x = Year, y = percentage, fill = Algorithm_type)) + 
  geom_area() +
  theme(legend.position = "bottom", legend.direction = "vertical") + 
  labs(x = "", y = "Article proportion", title = "Algorithm type by year")
```

##### Year vs journal discipline stacked area chart

A stacked area plot showing yearly changes in the counts of publications by journal discipline.   

```{r plot years and algorithms, fig.dim = c(8, 4)}
rawdata_incl$Journal_discipline <- as.factor(rawdata_incl$Journal_discipline)
# Give a specific order:
rawdata_incl$Journal_discipline <- factor(rawdata_incl$Journal_discipline, levels=c("multidisciplinary", "ecology", "computer science / technology"))

rawdata_incl %>% 
  filter(!is.na(Journal_discipline)) %>% 
  filter(Journal_discipline != "unclear/other") %>%   
  count(Journal_discipline, Year) %>%
  ggplot(aes(x = Year, y = n, fill = Journal_discipline)) + 
  geom_area() +
  theme(legend.position = "bottom", legend.direction = "vertical") + 
  labs(x = "", y = "Article count", title = "Journal discipline by year")
```

#### Individual recognition by species

A barplot of species names for studies focusing on re-identification of individuals. Species names were extracted only from papers focusing on a single species (i.e. data not shown for 12 multi-species studies).      

```{r plot indiv recognition species, fig.dim = c(8, 4)}
Outcome_type_sep_indiv <- Outcome_type_sep %>% 
  filter(Outcome_type == "individual recognition (re-identification)") 
#table(Outcome_type_sep_indiv$Study_species, useNA = "always") #0 NA

Outcome_type_sep_indiv %>% filter(Species_number == "1") %>% 
  filter(Outcome_type == "individual recognition (re-identification)") %>% 
  filter(Study_species != "unclear") %>% 
  count(Study_species) %>%
  arrange(n) %>%
  mutate(class=factor(Study_species, levels = Study_species)) %>%
  ggplot(aes(x = class, y = n)) +
  geom_bar(stat = "identity", position = "dodge") +
 # geom_text(aes(label=scales::comma(n)), hjust = 0, nudge_y = 1) +
  coord_flip() +
  scale_y_continuous(breaks = seq(0, 20, 1)) +
  labs(x = "", y = "Article count", title = "Most popular species for infividual recognition studies?",  caption = "Note: ignored 12 multi-species studies") #species names not extracted from multi-species indiv. recognition studies
```

Phylogenetic tree of species used in studies focusing on re-identification of individuals. Species names were extracted only from papers focusing on a single species (i.e. data not shown for 12 multi-species studies). Using rotl R package (https://peerj.com/preprints/1471/) allowing access to synthetic phylogenetic tree available at the Open Tree of Life database (https://opentreeoflife.org/).   
     
```{r prep indiv recognition species tree, message = FALSE, warning = FALSE, echo = FALSE}
#extract a vector of species names
myspecies <- Outcome_type_sep_indiv %>% filter(Species_number == "1") %>% 
  filter(Outcome_type == "individual recognition (re-identification)") %>% 
  filter(Study_species != "unclear")
myspecies <- unique(myspecies$Study_species)

## Using *rotl* package to retrieve synthetic species tree from Open Tree of Life
# taxa <- tnrs_match_names(names = myspecies)
# dim(taxa) #13 species
# table(taxa$approximate_match) #1 approximate match 
# taxa[taxa$approximate_match==TRUE, ] #delphinus spp.  to Delphineis sp. (this will throw an error if not fixed)
#replace with Cephalorhynchus hectori (Hector's dolphin)
myspecies <- gsub("Delphinus spp.", "Cephalorhynchus hectori", myspecies) #replace with the temporal name
taxa <- tnrs_match_names(names = myspecies)

## retrieve the initial tree - 
tree <- tol_induced_subtree(ott_ids = taxa[["ott_id"]], label_format = "name")
tree$tip.label <- gsub("Cephalorhynchus_hectori", "Delphinus_spp.", tree$tip.label) #replace with the original name
tree$tip.label[tree$tip.label == "Pan"] <- "Pan_troglodytes" #fix the name

## simple plot
#plot(tree, cex=.6, label.offset =.1, no.margin = TRUE)

tree <- write.tree(tree, file = here::here("data", "species_tree.tre")) #read saved tree
```

```{r plot indiv recognition species tree, fig.dim = c(8, 3), message = FALSE, warning = FALSE, echo = FALSE}
tree <- read.tree(file = here::here("data", "species_tree.tre")) #read saved binary tree (a few polytomies 

#tree$tip.label
tree$tip.label <- gsub("_"," ", tree$tip.label) #get rid of the underscores

myspecies_data <- Outcome_type_sep_indiv %>% filter(Species_number == "1") %>% 
  filter(Outcome_type == "individual recognition (re-identification)") %>% 
  filter(Study_species != "unclear") %>% group_by(Study_species) %>%
	summarise(count_studies = n(), biological_group = first(Studied_species_type))

#colnames(myspecies_data)

#length(intersect(tree$tip.label, myspecies_data$Study_species)) #13 - all species names match
#setdiff(tree$tip.label, myspecies_data$Study_species) #0 - all species names match
#setdiff(myspecies_data$Study_species, tree$tip.label) #
#prep for plotting bars of article counts
myspecies_counts <- myspecies_data$count_studies
names(myspecies_counts) <- myspecies_data$Study_species #add row names

#set colors for the biological groups information
color_bgroup <- recode(myspecies_data$biological_group, "fishes" = "#00A1D5", "mammals" = "#325F8C")
#assign colors to biological groups, https://r-charts.com/color-palettes/

names(color_bgroup) <- myspecies_data$Study_species #make it a named vector
color_bgroup_tip <- color_bgroup[match(tree$tip.label, names(color_bgroup))]  # reorder colors to match the order of tips on the tree

#plot locally
opar <- par(mar=c(4,0,1,1))
plot(tree, x.lim = 100, y.lim = 15, cex = 1, tip.color = color_bgroup_tip, label.offset = 1)
phydataplot(myspecies_counts, tree, offset = 60, scaling = 5, border = "white", col = color_bgroup_tip, cex.axis = 0.8)
text(84, 14, "Article count", cex=1.1) #col = "#325F8C", 
text(21, 14, "Species", cex=1.1) #col = "#325F8C", 
title("Individual recognition (re-identification)")
```

Overlay organism silhouettes

Note: phylopic.org hosts free silhouette images of animals, plants, and other life forms, all under Creative Commons or Public Domain. Also using colours to indicate biological groups across the plot.

```{r tree plot with siluettes, eval = TRUE}

#collect images using package rphylopic:
Pan <- image_data("7133ab33-cc79-4d7c-9656-48717359abb4", size = 128)[[1]]
Eubalaena <- image_data("fb533874-aa63-4f76-baf0-e9ceacd7333c", size = 128)[[1]]
Cephalorhynchus <- image_data("0d20875b-a4cd-4b87-98ec-080aff1c2c38", size = 128)[[1]]
Gorilla <- image_data("d9af529d-e426-4c7a-922a-562d57a7872e", size = 128)[[1]]
Megaptera <- image_data("ce70490a-79a5-47fc-afb9-834e45803ab4", size = 128)[[1]]
Pusa <- image_data("157b50ce-b330-4315-b2cd-53a0fa681d10", size = 128)[[1]]
Panthera <- image_data("e148eabb-f138-43c6-b1e4-5cda2180485a", size = 128)[[1]]
Ursus <- image_data("a12876cb-0930-4310-8ea8-2378df8164e3", size = 128)[[1]]
Sousa <- image_data("7bed394a-90e1-4da0-9d07-5b080a2061f4", size = 128)[[1]]
Macaca <- image_data("eedde61f-3402-4f7c-9350-49b74f5e1dba", size = 128)[[1]]
Grampus <- image_data("78d1f7fa-aece-4f92-bacf-843418d95723", size = 128)[[1]]
Ailuropoda <- image_data("4b1f7a58-8713-4d6e-a130-4c8a1ac2f749", size = 128)[[1]]
Salmo <- image_data("7f2cbb42-12b1-4481-8ac0-705eb7363c74", size = 128)[[1]]

#plot to pdf - with animal silouettes
pdf(file=here::here("plots", "Figure_tree_v0.pdf"), width=14, heigh=10)
par(oma=c(0,0,0,0)) 
par(mar=c(3,0,1,0) + 0.1)
plot(tree, x.lim = 100, y.lim = 15, cex = 1, tip.color = color_bgroup_tip, label.offset = 1)
phydataplot(myspecies_counts, tree, offset = 60, scaling = 5, border = "white", col = color_bgroup_tip, cex.axis = 0.8)
text(84, 14, "Article count", cex=1.1) #col = "#325F8C", 
text(21, 14, "Species", cex=1.1) #col = "#325F8C", 
title("Individual recognition (re-identification)")
add_phylopic_base(Salmo, x = 60, y = 13, ysize = 0.8, xsize = 8, color = "#00A1D5", alpha = 0.6)
add_phylopic_base(Panthera, x = 60, y = 12, ysize = 1, xsize = 12, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Pusa,x = 60, y = 11, ysize = 1, xsize = 10, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Ailuropoda, x = 60, y = 10, ysize = 1, xsize = 6, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Ursus, x = 60, y = 9, ysize = 1, xsize = 11, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Eubalaena, x = 60, y = 8, ysize = 1, xsize = 12, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Megaptera, x = 60, y = 7, ysize = 1, xsize = 10, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Sousa, x = 60, y = 6, ysize = 1, xsize = 10, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Cephalorhynchus, x = 60, y = 5, ysize = 1, xsize = 12, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Grampus, x = 60, y = 4, ysize = 1, xsize = 12, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Gorilla, x = 60, y = 3, ysize = 1, xsize = 6, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Pan, x = 60, y = 2, ysize = 0.8, xsize = 6, color = "#325F8C", alpha = 0.7)
add_phylopic_base(Macaca, x = 60, y = 1, ysize = 1, xsize = 8, color = "#325F8C", alpha = 0.7)
text(84, 14, "Article count", cex=1.1) #col = "#325F8C", 
text(21, 14, "Species", cex=1.1) #col = "#325F8C", 
title("Individual recognition (re-identification)")
dev.off()

```
Note: Plotting to pdf causes some of the animal silhouettes to have distorted height:width ratios - these will be fixed manually in Adobe Illustrator (saved as Figure2_tree_Ai.pdf)
   

#### Reporting quality

Table of counts of studies with unclear or missing data for key extracted variables (as applicable).   

```{r prep reporting quality unclear or NA}
## make a table with count of clear ( = sufficient) and unclear/missing (insufficient) / NA:
table_unclear <- rbind(table(rawdata_incl$Species_number == "NA"),
                       table(rawdata_incl$Study_species == "unclear"),
                       table(Studied_species_type_sep$Studied_species_type == "unclear"),
                       table(Image_source_type_sep$Image_source_type == "other / unclear"),
                       table(Study_setting_sep$Study_setting == "other / unclear"),
                       table(Location_country_sep$Location_country == "unclear"),
                       table(coordinates_sep$Approximate_location == "yes"),
                       table(Algorithm_type_sep$Algorithm_type == "other / unclear"),
                       table(Outcome_type_sep$Outcome_type == "other / unclear") )

colnames(table_unclear) <- c("sufficient", "insufficient") #rename table columns 
table_unclear <- data.frame(table_unclear) #change to data frame  
table_unclear$variable <-  c("Species/class number", "Single species/class name", "Study species type", "Image source type", "Study setting", "Location country", "In the wild location", "Algorithm type", "Outcome type") #prepare labels

#reshape dataframe into vertical:
table_unclear_long <- gather(table_unclear, reporting, value, insufficient:sufficient)
```

A stacked barplot of counts of studies with unclear and missing data for key extracted variables (as applicable).      
```{r plot reporting quality unclear or NA, fig.dim = c(8, 4)}
ggplot(table_unclear_long, aes(fill = reporting, y = value, x = variable)) + 
  geom_bar(position = "fill", stat = "identity") +
  coord_flip() +
  theme(legend.position = "top") +
  labs(x = "", y = "Proportion", title = "Reporting quality of study aspects?",  caption = "Note: assessed as relevant and including when inferred from other sources") #species names not extracted from multi-species studies
```

### Bibliometric analyses

These analyses are based on the information extracted from bibliographic records downloaded from Scopus. Initial preprocessing and summaries using bibliometrix R package. Subsequently this data was combined with manually coded data from the full texts.   

#### First author country 

Load and export author affiliation country from bibliographic records (*scopus_AI_1and2.bib*). 

```{r load bib, message = FALSE}
bib <- convert2df(here("data", "scopus_AI_1and2.bib"), dbsource = "wos", format = "bibtex") #does not load with dbsource = "wos"

#names(bib)
#dim(bib) #2259 38
#bib$CR[1] #no Cited References
#main field tags are listed in: https://www.bibliometrix.org/vignettes/Data-Importing-and-Converting.html
#For a complete list of WoS field tags (used in bibliometrix), see https://www.bibliometrix.org/documents/Field_Tags_bibliometrix.pdf
```

Initial data cleaning and merging with manually coded data frame. Standard bibliometric data summary.      

```{r merge by titles , eval=TRUE}
# Removing all non-alphanumeric, punctuation and extra white spaces in bib object
bib$TI2 <- gsub("[^[:alnum:] ]", "", bib$TI) %>% str_replace_all(.,"[ ]+", " ")

# Remove all non-alphanumeric, punctuation and extra white spaces in rawdata_incl object
rawdata_incl$TI2 <- str_to_upper(gsub("[^[:alnum:] ]", "", rawdata_incl$Title)) %>% str_replace_all(.,"[ ]+", " ")

# Merge info from bib object to rawdata_incl by TI2
#bib_title <- left_join(rawdata_incl, bib, by = "TI2")
#dim(bib_title) #192 57
#table(is.na(bib_title$TI)) #6 has no title from WoS
#View(bib_title[is.na(bib_title$TI), c("TI2", "TI")]) #odd characters in the titles messing up matching and merging step: \r\ , âˆšÂ°, -, Ã„â€ , ``

# clean-up of 6 non-matching titles before merging - replace title TI2 in bib (not-matching) with TI2  from rawdata_incl
bib[bib$TI2 %like% "MODELLING WILDLIFE SPECIES ABUNDANCE USING", "TI2"] <- rawdata_incl[rawdata_incl$TI2 %like% "MODELLING WILDLIFE SPECIES ABUNDANCE USING", "TI2"]
bib[bib$TI2 %like% "COUNTING BREEDING GULLS", "TI2"] <- rawdata_incl[rawdata_incl$TI2 %like% "COUNTING BREEDING GULLS", "TI2"]
bib[bib$TI2 %like% "COMPARING CLASSAWARE AND PAIRWISE LOSS FUNCTIONS", "TI2"] <- rawdata_incl[rawdata_incl$TI2 %like% "COMPARING CLASSAWARE AND PAIRWISE LOSS FUNCTIONS", "TI2"]
bib[bib$TI2 %like% "BELUGA WHALE DETECTION IN THE CUMBERLAND", "TI2"] <- rawdata_incl[rawdata_incl$TI2 %like% "BELUGA WHALE DETECTION IN THE CUMBERLAND", "TI2"]
bib[bib$TI2 %like% "REVEALING THE UNKNOWN REALTIME RECOGNITION OF", "TI2"] <- rawdata_incl[rawdata_incl$TI2 %like% "REVEALING THE UNKNOWN REALTIME RECOGNITION OF", "TI2"]

#join the dataframes
bib_title <- left_join(rawdata_incl, bib, by = "TI2")
#dim(bib_title) #192 57
#names(bib_title)

# table(is.na(bib_title$TI)) #all 192 have title
# table(is.na(bib_title$AU)) #0 has no author names
# table(is.na(bib_title$DE)) #51 has no author keywords
# table(is.na(bib_title$author_keywords)) #29 has no author keywords here
# table(is.na(bib_title$C1)) #0 has no author affiliations
# table(is.na(bib_title$AB)) #6 has no abstract
# table(is.na(bib_title$url)) #0 has no url 
# table(is.na(bib_title$TC)) #0 is missing, but all values are 0! 
# table(is.na(bib_title$RP)) #0 has no corresponding author affiliation
# table(is.na(bib_title$correspondence_address1)) #68 here has no corresponding author affiliation
# table(is.na(bib_title$funding_details)) # 91 has no funding details

results <- biblioAnalysis(bib_title, sep = ";") #this calculates the main bibliometric measures, displaying main info about the bibliographic data frame 
#names(results)
#plot(results, k = 50, pause = FALSE) #plots selected graphs
results_summary <- summary(object = results, k = 10, pause = FALSE) #summary tables
#str(results_summary) #lists of results from 9 analyses/tables
#results_summary$MainInformationDF
#results_summary$MostProdCountries
#results_summary$MostRelSources
#hist(results$nAUperPaper) #number of authors per paper
#results$DE[1:10] #top author keywords

#interpreting results object: https://search.r-project.org/CRAN/refmans/bibliometrix/html/biblioAnalysis.html
```

A barplot of country assigned to each publication based on the affiliation country of the first author. Co-authorship type is based on country of all authors of a given publication. SCP indicates all authors were affiliated with  the same country. MCP indicates international co-authorship.   

```{r plot first author country collab type, fig.dim = c(8, 6)}

# results$Countries #number of papers by country of first author
# results$CountryCollaboration #number of papers by country of first author by paper authorship type

#reshape dataframe into long format:
CountryCollaboration_ord <- results$CountryCollaboration
CountryCollaboration_ord$Country <- factor(CountryCollaboration_ord$Country)
CountryCollaboration_long <- gather(CountryCollaboration_ord, Collaboration, value, MCP:SCP, factor_key=TRUE)
#reorder by total frequency
CountryCollaboration_long$Country <- factor(CountryCollaboration_ord$Country, levels = levels(reorder(CountryCollaboration_ord$Country, rowSums(CountryCollaboration_ord[-1]))) )

CountryCollaboration_long %>%
  arrange(value) %>%
  ggplot(aes(fill = Collaboration, y = value, x = Country)) + 
  geom_bar(stat = "identity") +
  coord_flip() +
  theme(legend.position = "top") +
  labs(x = "", y = "Proportion", title = "Author collaboration type by country?",  caption = "SCP: Single Country Publications, MCP: Multiple Country Publications")
```

#### Country publication counts and co-authorship types

A choropleth map of the counts of articles with their first author affiliated with a given country.  

```{r plot countries of first authors, fig.dim = c(8, 5)}
#table(results$CO, useNA = "always") #19 NA, country of first author, see: https://search.r-project.org/CRAN/refmans/bibliometrix/html/biblioAnalysis.html
FAuthor_country <- str_to_title(results$CO)
#table(FAuthor_country, useNA = "always") #fix USA and UK, Korea
FAuthor_country <- recode(FAuthor_country, "Usa" = "USA")
FAuthor_country <- recode(FAuthor_country, "United Kingdom" = "UK")
FAuthor_country <- recode(FAuthor_country, "Korea" = "South Korea")

#table(FAuthor_country) #40

map.world <- map_data("world")
#intersect(map.world$region, FAuthor_country) #40 out of 40 found

table(FAuthor_country) %>% 
  data.frame() -> FAuthor_country_counts
#str(Location_country_counts)    

map.world_joined_FA <- left_join(map.world, FAuthor_country_counts, by = c('region' = 'FAuthor_country'))
#map.world_joined_FA$Freq

ggplot(map.world_joined_FA, aes(long, lat, group = group)) +
  geom_polygon(aes(fill = Freq ), color = "white") +
  scale_fill_viridis_c(option = "E") +
  labs(title = 'Most common first author country?') +
  theme(legend.position = "bottom")
```

A choropleth map of the counts of articles with their first author affiliated with a given country (using different colour scheme), with image collection locations presented as points. Locations represent either a specific study site (green circles) or centroids of a broader region (orange circles) animal images originated from. Darker circles indicate a larger number of studies using images from a given location. Global image datasets (e.g. gathered from the Internet or social media) are not shown.    

```{r plot location coordinates authors countries, fig.dim = c(8, 4)}
#base don https://datavizpyr.com/how-to-make-world-map-with-ggplot2-in-r/

ggplot() +
  geom_map( data = map.world_joined_FA,
            map = map.world_joined_FA,
            mapping = aes(map_id = region, fill = Freq),
            size=0.1,
            colour="grey" ) +
  expand_limits(x = map.world_joined_FA$long, y = map.world_joined_FA$lat) +
  coord_fixed() +
  labs(title = 'First author country and wild data locations?', x = "", y = "") +
  geom_point(
    data = coordinates_sep,
    aes(Longitude, Latitude, color = Approximate_location), size = 2,
    alpha = 0.5, position = position_jitter(width = 2, height = 2)
  )  +
  scale_colour_manual(values = c("darkgreen", "orange")) +
  theme(legend.position = "bottom")
```

```{r match countries of first authors to locations , fig.dim = c(8, 4)}
#add to main data frame and clean
bib_title$Author_country <- str_to_title(results$CO)
#table(bib_title$Author_country) #fix USA and UK
bib_title$Author_country <- recode(bib_title$Author_country, "Usa" = "USA")
bib_title$Author_country <- recode(bib_title$Author_country, "United Kingdom" = "UK")

#split by Location_country at comma
bib_title_locations <- separate_rows(bib_title, Location_country, sep = ", ") #split rows with multiple values
# dim(bib_title_locations) #216
# length(unique(bib_title_locations$Location_country)) #48 total, includes unclear
# table(bib_title_locations$Location_country, useNA = "always") #0 NA, 11 unclear, global Antarctica, Arctic
# length(unique(bib_title_locations$Author_country)) #41 total - focus on these qith >1 study
# table(bib_title_locations$Author_country, useNA = "always") #20 NA - try to fill in manually?

# intersect(unique(bib_title_locations$Location_country), unique(bib_title_locations$Author_country)) #24 overlapping
# setdiff(unique(bib_title_locations$Location_country), unique(bib_title_locations$Author_country)) #24 non-overlapping
# setdiff(unique(bib_title_locations$Author_country), unique(bib_title_locations$Location_country)) #17 non-overlapping

#names(bib_title_locations)           
countries_overlap <- data.table(table(bib_title_locations$Location_country, bib_title_locations$Author_country))
names(countries_overlap) <- c('location', 'author', 'freq')
```

An alluvial plot representing overlaps of countries of affiliation of study first author and countries / regions where image data originated from. Data in global and unclear locations are included in the plot.     

```{r alluvial countries of first authors vs locations , fig.dim = c(8, 7)}
#https://r-charts.com/flow/ggalluvial/

countries_overlap2 <- countries_overlap %>% filter(freq > 1) #only countries with >1 papers

ggplot(data = countries_overlap2,
       aes(axis1 = author, axis2 = location, y = freq, legend.position = "none")) +
  geom_alluvium(aes(fill = author)) +
  geom_stratum(color = "grey") +
  geom_text(stat = "stratum", #color="white",
            aes(label = after_stat(stratum))) +
  scale_x_discrete(limits = c("author", "location"),
                   expand = c(0.15, 0.05)) +
  scale_fill_viridis_d() +
  labs(title = "Author country vs. study location",  caption = "Note: by first author country, only countries with >1 paper") +
  theme_void() +
  theme(legend.position = "none", axis.text.x = element_text(size=10, face = "italic")) 
```

An choropleth map showing overlaps of countries of affiliation of study first author and locations where image data originated from. Data in global and unclear locations are not included in the plot.  Arrows link locations of images to locations of ex situ authors (i.e. authors working on image datasets from a different country / region) and bubbles represent in situ authors (i.e. authors working on image datasets from the same country / region), scaled proportionally to article counts. Multi-country / global image datasets (e.g. gathered from the Internet or social media) are not shown.   

```{r prep connections countries of first authors to locations}
#https://stackoverflow.com/questions/9872700/plotting-email-flow-in-map-using-r/9872981
#https://stackoverflow.com/questions/59336249/plot-connections-between-countries

worldmap <- getMap() #use data from package rworldmap
worldmap_names <- select(as.data.frame(worldmap), NAME)
worldmap_names <- levels(worldmap_names$NAME) #a twisted way of making it into character vector

## my countries
# length(unique(countries_overlap$author))#40
# length(unique(countries_overlap$location))#48
## check overlap
# intersect(unique(countries_overlap$author), worldmap_names) #35/40
# setdiff(unique(countries_overlap$author), worldmap_names) #"Czech Republic", "Korea", "UK", "USA", "Western Indian Ocean"
# intersect(unique(countries_overlap$location), worldmap_names) #38/48
# setdiff(unique(countries_overlap$location), worldmap_names) #"Africa","Arctic","Falkland Islands","global","North Atlantic","Norwegian Sea","Republic of Congo", "South Korea", "UK", "unclear", "USA"

## recode some country names (others will be omitted if too generic or unclear)
countries_overlap$author <- recode(countries_overlap$author , "USA" = "United States", "Western Indian Ocean" = "Mauritius", "Korea" = "S. Korea", "UK" = "United Kingdom", "Czech Republic" = "Czech Rep.", "Republic of Congo" = "Congo (Brazzaville)", "Norwegian Sea" = "Faroe Is.", "Falkland Islands" = "Falkland Is.")
countries_overlap$location <- recode(countries_overlap$location , "USA" = "United States", "Western Indian Ocean" = "Mauritius", "Korea" = "S. Korea", "UK" = "United Kingdom", "Czech Republic" = "Czech Rep.", "Republic of Congo" = "Congo (Brazzaville)", "Norwegian Sea" = "Faroe Is.", "Falkland Islands" = "Falkland Is.")


#select only countries with >0 papers, select only where location not global and not unclear
countries_overlap2 <- countries_overlap %>% filter(freq > 0) %>% filter(location != "unclear") %>% filter(location != "global") 

## check overlap author-location country lists
# intersect(countries_overlap2$author, countries_overlap2$location) #23 in both sets
# setdiff(countries_overlap2$author, countries_overlap2$location) #8 have no matching locations
# setdiff(countries_overlap2$location, countries_overlap2$author) #21 have no matching authors

#add country colors
countries_overlap2$color_location <- as.factor(countries_overlap2$location) #colours by location
#assign evenly spaced colors from viridis scale by location country
levels(countries_overlap2$color_location) <- scales::viridis_pal(alpha = 0.5, option = "D")(length(unique(countries_overlap2$color_location)))
#plot(c(1:length(unique(countries_overlap2$color_location))), pch=19, cex=2, col=scales::viridis_pal(alpha = 0.5, option = "D")(length(unique(countries_overlap2$color_location)))) #check colours

#assign matching colours to author countries
countries_overlap2$color_author <- countries_overlap2$color[match(countries_overlap2$author, countries_overlap2$location)]

#assign brown to countries with NA
countries_overlap2$color_author %>% as.character() %>% replace_na("#A9A9A9FF") -> countries_overlap2$color_author

# add latitude and longitude to each country 
countries_overlap2 <- countries_overlap2 %>%
  left_join(select(as.data.frame(worldmap), NAME, LON, LAT),
             by = c("location" = "NAME")) %>%
  left_join(select(as.data.frame(worldmap), NAME, LON, LAT),
             by = c("author" = "NAME"))

# split int subsets for plotting lines and circles
countries_overlap2_diff <- filter(countries_overlap2, location != author) #end points must not be identical for connecting lines
countries_overlap2_same <- filter(countries_overlap2, location == author) # points with the same countries - use for points
```

```{r plot connections countries of first authors to locations , fig.dim = c(8, 6)}
ggplot() + 
  geom_polygon(data = worldmap, aes(long, lat, group=group), fill="gray") +
  geom_curve(data = countries_overlap2_diff, aes(x = LON.x, y = LAT.x, xend = LON.y, yend = LAT.y),
             curvature = -0.2, arrow = arrow(type = "open", length = unit(0.02, "npc")), colour = countries_overlap2_diff$color_location) +
  labs(title = 'Data country to first author country?', x = "", y = "") +
  geom_point(
    data = countries_overlap2_same,
    aes(LON.x, LAT.x, color = color_author), size = countries_overlap2_same$freq,
    alpha = 0.5, position = position_jitter(width = 1, height = 1)
  ) +
  labs(title = "Author country vs. study location",  caption = "Note: data by first author country") +
  theme_void() +
  theme(legend.position = "none") 
```

### DONE since previous
- classify journals into comp.sci vs. ecology journals - DONE
- plot for year vs. algorithm type - DONE
- plot for year vs. outcome type - DONE
- individual recognition for which species? - DONE
- reporting quality - DONE
- bibliometric analyses: affiliation country distribution (first author, all authors, within-study diversity) and overlap with study location - DONE

### NEXT 
- decide the main points for the manuscript (e.g. taxonomic and geographic biases, poor reporting quality)
- single or multiple datasets e.g. training on captive but analysisng in the wild? Number of datasets? Type of datasets (custom vs. generic)? - DISCUSS after reading the MS draft
- add any additional data needed (e.g. use of generic vs custom datasets, extract many species from individual recognition studies) . For types of animals used - how many focused on one type vs. many?
- select and make plots for presentation in the main text (e.g. funcier species tree with isons and barplots of counts?)
- make a multi-panel figure for the main text

